seed: 4294967295

trainer:
  max_epochs: 2
  accelerator: auto
  devices: auto
  precision: 32-true
  log_every_n_steps: 10

model:
  name: monai.unet # For models from MONAI, use 'monai.<model_name>'
  optim:
    name: adam
    lr: 1e-3
    weight_decay: 0.0
  scheduler:
    name: null  # Options: cosine, reduce_on_plateau, step, exponential
    params: {}
  metrics:
    - dice  # Options: dice, hausdorff (requires MONAI)
  params:
    in_channels: 1
    out_channels: 1
    channels: [16, 32, 64, 128]
    strides: [2, 2, 2]
    num_res_units: 2
    norm: batch
    loss: bce  # or "dice"

data:
  name: medical2d
  batch_size: 2
  num_workers: 2
  params:
    json_train: null  # path to JSON file with train data: [{"image": "path/to/img", "label": "path/to/label"}]
    json_val: null    # path to JSON file with validation data
    # This framework does not support performance evaluation via test set yet, but this can be added in future releases
    cache_rate: 0.0   # fraction of data to cache in memory (0.0-1.0)
    synthetic: true   # For testing purposes: if true, use a tiny synthetic fallback dataset (torch required)

logger:
  wandb:
    project: dtt
    name: null
    entity: null
    tags: ["template", "dtt"]
    mode: offline

callbacks:
  model_checkpoint:
    monitor: val/loss
    save_top_k: 1
    mode: min
    filename: epoch{epoch:02d}-valloss{val/loss:.3f}
    save_last: true
    verbose: false
  early_stopping:
    monitor: val/loss
    patience: 5
    mode: min
    min_delta: 0.0
    verbose: false
  lr_monitor:
    logging_interval: epoch
    log_momentum: false
